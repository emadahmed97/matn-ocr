#!/usr/bin/env python3
"""
Comprehensive Arabic text characteristics analysis for Classical Islamic manuscripts.

This script analyzes the MohamedRashad/arabic-books dataset to understand:
- Diacritic patterns and frequency
- Classical Islamic text formatting
- Character distribution and patterns
- Manuscript-specific linguistic features
"""

import re
import unicodedata
from collections import Counter, defaultdict
from typing import Dict, List, Tuple
# from datasets import load_dataset  # Not needed for sample analysis


class ArabicTextCharacteristicsAnalyzer:
    """Analyzes Arabic text characteristics for OCR training."""

    def __init__(self):
        """Initialize the analyzer with Arabic text processing capabilities."""

        # Extended diacritics list
        self.diacritics = {
            '\u064B': 'Fathatan',     # Ù‹
            '\u064C': 'Dammatan',     # ÙŒ
            '\u064D': 'Kasratan',     # Ù
            '\u064E': 'Fatha',        # Ù
            '\u064F': 'Damma',        # Ù
            '\u0650': 'Kasra',        # Ù
            '\u0651': 'Shadda',       # Ù‘
            '\u0652': 'Sukun',        # Ù’
            '\u0653': 'Maddah',       # Ù“
            '\u0654': 'Hamza above',  # Ù”
            '\u0655': 'Hamza below',  # Ù•
            '\u0656': 'Subscript alef', # Ù–
            '\u0657': 'Inverted damma', # Ù—
            '\u0658': 'Mark noon ghunna', # Ù˜
        }

        # Arabic letters
        self.arabic_letters = list(range(0x0627, 0x064A + 1))  # Ø§ to ÙŠ

        # Classical Islamic terminology patterns
        self.islamic_patterns = [
            r'Ø§Ù„Ù„Ù‡',           # Allah
            r'Ø±Ø³ÙˆÙ„',          # Messenger
            r'Ø§Ù„Ù†Ø¨ÙŠ',          # The Prophet
            r'ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù…', # PBUH
            r'Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡',    # May Allah be pleased with him
            r'Ø±Ø­Ù…Ù‡ Ø§Ù„Ù„Ù‡',       # May Allah have mercy on him
            r'Ø¹Ù„ÙŠÙ‡ Ø§Ù„Ø³Ù„Ø§Ù…',     # Peace be upon him
            r'ØªØ¹Ø§Ù„Ù‰',          # Most High
            r'Ø³Ø¨Ø­Ø§Ù†Ù‡',         # Glory be to Him
            r'Ø¨Ø§Ø¨',            # Chapter
            r'ÙƒØªØ§Ø¨',           # Book
            r'ÙØµÙ„',            # Section
            r'Ø­Ø¯ÙŠØ«',           # Hadith
            r'Ù‚Ø§Ù„',            # He said
            r'Ø¹Ù†',             # From/About
        ]

        # Manuscript formatting patterns
        self.formatting_patterns = {
            'chapter_headers': [r'ÙƒØªØ§Ø¨\s+\w+', r'Ø¨Ø§Ø¨\s+\w+', r'ÙØµÙ„\s+\w+'],
            'numbered_lists': [r'[Ù¡-Ù©]+\.', r'[1-9]+\.', r'[Ø£-ÙŠ]\.'],
            'citations': [r'Ù‚Ø§Ù„\s+\w+', r'ÙˆØ¹Ù†\s+\w+', r'Ø­Ø¯Ø«Ù†Ø§\s+\w+'],
            'references': [r'Ø±ÙˆØ§Ù‡\s+\w+', r'Ø£Ø®Ø±Ø¬Ù‡\s+\w+', r'Ø°ÙƒØ±Ù‡\s+\w+'],
        }

    def analyze_diacritics(self, text: str) -> Dict:
        """Analyze diacritic patterns in text."""
        diacritic_counts = Counter()
        total_chars = len(text)
        arabic_chars = 0

        # Count characters and diacritics
        for char in text:
            if '\u0600' <= char <= '\u06FF':  # Arabic block
                arabic_chars += 1
                if char in self.diacritics:
                    diacritic_counts[self.diacritics[char]] += 1

        # Calculate statistics
        total_diacritics = sum(diacritic_counts.values())
        diacritic_ratio = total_diacritics / arabic_chars if arabic_chars > 0 else 0

        return {
            'total_chars': total_chars,
            'arabic_chars': arabic_chars,
            'diacritic_counts': dict(diacritic_counts),
            'total_diacritics': total_diacritics,
            'diacritic_ratio': diacritic_ratio,
            'most_common_diacritics': diacritic_counts.most_common(5)
        }

    def analyze_formatting_patterns(self, text: str) -> Dict:
        """Analyze manuscript formatting patterns."""
        results = {}

        for pattern_type, patterns in self.formatting_patterns.items():
            matches = []
            for pattern in patterns:
                found = re.findall(pattern, text, re.UNICODE)
                matches.extend(found)
            results[pattern_type] = {
                'count': len(matches),
                'examples': matches[:5]  # First 5 examples
            }

        return results

    def analyze_islamic_terminology(self, text: str) -> Dict:
        """Analyze Islamic terminology frequency."""
        term_counts = {}

        for pattern in self.islamic_patterns:
            matches = re.findall(pattern, text, re.UNICODE)
            if matches:
                term_counts[pattern] = len(matches)

        return {
            'term_frequencies': term_counts,
            'total_islamic_terms': sum(term_counts.values()),
            'unique_terms': len(term_counts)
        }

    def analyze_character_distribution(self, text: str) -> Dict:
        """Analyze character frequency distribution."""
        char_counts = Counter()

        for char in text:
            if '\u0600' <= char <= '\u06FF':  # Arabic block
                char_counts[char] += 1

        # Get most common characters
        most_common = char_counts.most_common(20)

        return {
            'character_frequencies': dict(char_counts),
            'most_common_chars': most_common,
            'unique_characters': len(char_counts),
            'total_arabic_chars': sum(char_counts.values())
        }

    def analyze_text_structure(self, text: str) -> Dict:
        """Analyze overall text structure."""
        lines = text.split('\n')
        words = text.split()

        # Line length analysis
        line_lengths = [len(line) for line in lines if line.strip()]
        avg_line_length = sum(line_lengths) / len(line_lengths) if line_lengths else 0

        # Word length analysis
        word_lengths = [len(word) for word in words]
        avg_word_length = sum(word_lengths) / len(word_lengths) if word_lengths else 0

        return {
            'total_lines': len(lines),
            'non_empty_lines': len(line_lengths),
            'total_words': len(words),
            'avg_line_length': avg_line_length,
            'avg_word_length': avg_word_length,
            'max_line_length': max(line_lengths) if line_lengths else 0,
            'min_line_length': min(line_lengths) if line_lengths else 0
        }


def analyze_dataset_sample():
    """Analyze sample classical Arabic Islamic texts."""
    print("ğŸ” Analyzing classical Arabic Islamic text samples...")

    analyzer = ArabicTextCharacteristicsAnalyzer()

    # Sample classical Islamic texts for analysis
    sample_texts = [
        """
        ÙƒØªØ§Ø¨ Ø§Ù„Ø·Ù‡Ø§Ø±Ø©

        Ø¨Ø§Ø¨ Ø§Ù„ÙˆØ¶ÙˆØ¡ ÙˆÙØ±Ø§Ø¦Ø¶Ù‡ ÙˆØ³Ù†Ù†Ù‡

        Ù‚Ø§Ù„ Ø§Ù„Ù„Ù‡ ØªØ¹Ø§Ù„Ù‰: ÙŠØ§ Ø£ÙŠÙ‡Ø§ Ø§Ù„Ø°ÙŠÙ† Ø¢Ù…Ù†ÙˆØ§ Ø¥Ø°Ø§ Ù‚Ù…ØªÙ… Ø¥Ù„Ù‰ Ø§Ù„ØµÙ„Ø§Ø© ÙØ§ØºØ³Ù„ÙˆØ§ ÙˆØ¬ÙˆÙ‡ÙƒÙ… ÙˆØ£ÙŠØ¯ÙŠÙƒÙ… Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø±Ø§ÙÙ‚ ÙˆØ§Ù…Ø³Ø­ÙˆØ§ Ø¨Ø±Ø¤ÙˆØ³ÙƒÙ… ÙˆØ£Ø±Ø¬Ù„ÙƒÙ… Ø¥Ù„Ù‰ Ø§Ù„ÙƒØ¹Ø¨ÙŠÙ†

        ÙˆØ¹Ù† Ø£Ø¨ÙŠ Ù‡Ø±ÙŠØ±Ø© Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡ Ù‚Ø§Ù„: Ù‚Ø§Ù„ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù…: Ù„Ø§ ÙŠÙ‚Ø¨Ù„ Ø§Ù„Ù„Ù‡ ØµÙ„Ø§Ø© Ø£Ø­Ø¯ÙƒÙ… Ø¥Ø°Ø§ Ø£Ø­Ø¯Ø« Ø­ØªÙ‰ ÙŠØªÙˆØ¶Ø£

        ÙØµÙ„ ÙÙŠ Ø¢Ø¯Ø§Ø¨ Ø§Ù„ÙˆØ¶ÙˆØ¡:
        Ù¡. Ø§Ù„Ø¨Ø³Ù…Ù„Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø¯Ø¡
        Ù¢. ØºØ³Ù„ Ø§Ù„ÙƒÙÙŠÙ† Ø«Ù„Ø§Ø«Ø§Ù‹
        Ù£. Ø§Ù„Ù…Ø¶Ù…Ø¶Ø© ÙˆØ§Ù„Ø§Ø³ØªÙ†Ø´Ø§Ù‚
        Ù¤. ØºØ³Ù„ Ø§Ù„ÙˆØ¬Ù‡ Ø«Ù„Ø§Ø«Ø§Ù‹
        Ù¥. ØºØ³Ù„ Ø§Ù„ÙŠØ¯ÙŠÙ† Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø±ÙÙ‚ÙŠÙ†
        """,

        """
        ÙƒØªØ§Ø¨ Ø§Ù„ØµÙ„Ø§Ø©

        Ø¨Ø§Ø¨ Ø£ÙˆÙ‚Ø§Øª Ø§Ù„ØµÙ„Ø§Ø© ÙˆØ´Ø±ÙˆØ·Ù‡Ø§

        Ø¹Ù† Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ø¨Ù† Ø¹Ù…Ø± Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ù…Ø§ Ù‚Ø§Ù„: Ù‚Ø§Ù„ Ø§Ù„Ù†Ø¨ÙŠ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù…: ÙˆÙ‚Øª Ø§Ù„Ø¸Ù‡Ø± Ø¥Ø°Ø§ Ø²Ø§Ù„Øª Ø§Ù„Ø´Ù…Ø³ ÙˆÙƒØ§Ù† Ø¸Ù„ Ø§Ù„Ø±Ø¬Ù„ ÙƒØ·ÙˆÙ„Ù‡ Ù…Ø§ Ù„Ù… ÙŠØ­Ø¶Ø± Ø§Ù„Ø¹ØµØ±ØŒ ÙˆÙˆÙ‚Øª Ø§Ù„Ø¹ØµØ± Ù…Ø§ Ù„Ù… ØªØµÙØ± Ø§Ù„Ø´Ù…Ø³

        Ø­Ø¯Ø«Ù†Ø§ Ù…Ø§Ù„Ùƒ Ø¹Ù† Ø²ÙŠØ¯ Ø¨Ù† Ø£Ø³Ù„Ù… Ø¹Ù† Ø¹Ø·Ø§Ø¡ Ø¨Ù† ÙŠØ³Ø§Ø± Ø¹Ù† Ø§Ø¨Ù† Ø¹Ø¨Ø§Ø³ Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡Ù…Ø§ Ø£Ù†Ù‡ Ù‚Ø§Ù„: Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø£Ø¨Ùˆ Ø³ÙÙŠØ§Ù† Ø£Ù† Ù‡Ø±Ù‚Ù„ Ù‚Ø§Ù„ Ù„Ù‡: Ø³Ø£Ù„ØªÙƒ Ø¹Ù† Ø§Ù„ØµÙ„Ø§Ø© ÙØ²Ø¹Ù…Øª Ø£Ù†Ù‡ ÙŠØ£Ù…Ø±ÙƒÙ… Ø¨Ù‡Ø§

        ÙØµÙ„ ÙÙŠ Ù‚Ø¨Ù„Ø© Ø§Ù„Ù…ØµÙ„ÙŠ:
        Ø£. Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù‚Ø¨Ù„Ø© Ø´Ø±Ø· Ù„ØµØ­Ø© Ø§Ù„ØµÙ„Ø§Ø©
        Ø¨. ØªØ­Ø±ÙŠ Ø§Ù„Ù‚Ø¨Ù„Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡
        Ø¬. Ø§Ù„ØµÙ„Ø§Ø© ÙÙŠ Ø§Ù„Ø·Ø§Ø¦Ø±Ø© ÙˆØ§Ù„Ø³ÙÙŠÙ†Ø©
        """,

        """
        ÙƒØªØ§Ø¨ Ø§Ù„Ø²ÙƒØ§Ø© ÙˆØ§Ù„ØµØ¯Ù‚Ø©

        Ø¨Ø§Ø¨ Ø²ÙƒØ§Ø© Ø§Ù„Ø°Ù‡Ø¨ ÙˆØ§Ù„ÙØ¶Ø©

        Ù‚Ø§Ù„ ØªØ¹Ø§Ù„Ù‰: ÙˆØ§Ù„Ø°ÙŠÙ† ÙŠÙƒÙ†Ø²ÙˆÙ† Ø§Ù„Ø°Ù‡Ø¨ ÙˆØ§Ù„ÙØ¶Ø© ÙˆÙ„Ø§ ÙŠÙ†ÙÙ‚ÙˆÙ†Ù‡Ø§ ÙÙŠ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù„Ù‡ ÙØ¨Ø´Ø±Ù‡Ù… Ø¨Ø¹Ø°Ø§Ø¨ Ø£Ù„ÙŠÙ…

        Ø¹Ù† Ø£Ø¨ÙŠ Ø³Ø¹ÙŠØ¯ Ø§Ù„Ø®Ø¯Ø±ÙŠ Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡ Ù‚Ø§Ù„: Ù‚Ø§Ù„ Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù…: Ù„ÙŠØ³ ÙÙŠÙ…Ø§ Ø¯ÙˆÙ† Ø®Ù…Ø³ Ø£ÙˆØ§Ù‚ Ù…Ù† Ø§Ù„ÙˆØ±Ù‚ ØµØ¯Ù‚Ø©ØŒ ÙˆÙ„ÙŠØ³ ÙÙŠÙ…Ø§ Ø¯ÙˆÙ† Ø®Ù…Ø³ Ø°ÙˆØ¯ Ù…Ù† Ø§Ù„Ø¥Ø¨Ù„ ØµØ¯Ù‚Ø©

        ÙˆØ¹Ù† Ø¹Ù„ÙŠ Ø¨Ù† Ø£Ø¨ÙŠ Ø·Ø§Ù„Ø¨ Ø±Ø¶ÙŠ Ø§Ù„Ù„Ù‡ Ø¹Ù†Ù‡ Ù‚Ø§Ù„: Ù‡Ø°Ù‡ ØµØ¯Ù‚Ø© Ø±Ø³ÙˆÙ„ Ø§Ù„Ù„Ù‡ ØµÙ„Ù‰ Ø§Ù„Ù„Ù‡ Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ø§Ù„ØªÙŠ ÙØ±Ø¶Ù‡Ø§ Ø§Ù„Ù„Ù‡ Ø¹Ø² ÙˆØ¬Ù„:
        Ù¡. ÙÙŠ Ø£Ø±Ø¨Ø¹ ÙˆØ¹Ø´Ø±ÙŠÙ† Ù…Ù† Ø§Ù„Ø¥Ø¨Ù„ ÙÙ…Ø§ Ø¯ÙˆÙ†Ù‡Ø§ Ø§Ù„ØºÙ†Ù… ÙÙŠ ÙƒÙ„ Ø®Ù…Ø³ Ø´Ø§Ø©
        Ù¢. ÙØ¥Ø°Ø§ Ø¨Ù„ØºØª Ø®Ù…Ø³Ø§Ù‹ ÙˆØ¹Ø´Ø±ÙŠÙ† Ø¥Ù„Ù‰ Ø®Ù…Ø³ ÙˆØ«Ù„Ø§Ø«ÙŠÙ† ÙÙÙŠÙ‡Ø§ Ø¨Ù†Øª Ù…Ø®Ø§Ø¶ Ø£Ù†Ø«Ù‰
        Ù£. ÙØ¥Ø°Ø§ Ø¨Ù„ØºØª Ø³ØªØ§Ù‹ ÙˆØ«Ù„Ø§Ø«ÙŠÙ† Ø¥Ù„Ù‰ Ø®Ù…Ø³ ÙˆØ£Ø±Ø¨Ø¹ÙŠÙ† ÙÙÙŠÙ‡Ø§ Ø¨Ù†Øª Ù„Ø¨ÙˆÙ† Ø£Ù†Ø«Ù‰

        ÙØµÙ„ ÙÙŠ Ø²ÙƒØ§Ø© Ø§Ù„Ø²Ø±ÙˆØ¹ ÙˆØ§Ù„Ø«Ù…Ø§Ø±:
        - Ø§Ù„Ù†ØµØ§Ø¨ ÙÙŠ Ø§Ù„Ø²Ø±ÙˆØ¹ ÙˆØ§Ù„Ø«Ù…Ø§Ø± Ø®Ù…Ø³Ø© Ø£ÙˆØ³Ù‚
        - Ø§Ù„ÙˆØ§Ø¬Ø¨ Ø§Ù„Ø¹Ø´Ø± Ø¥Ù† Ø³Ù‚ÙŠØª Ø¨Ù…Ø§Ø¡ Ø§Ù„Ù…Ø·Ø± ÙˆØ§Ù„Ø£Ù†Ù‡Ø§Ø±
        - Ø§Ù„ÙˆØ§Ø¬Ø¨ Ù†ØµÙ Ø§Ù„Ø¹Ø´Ø± Ø¥Ù† Ø³Ù‚ÙŠØª Ø¨Ø§Ù„Ø¯Ù„Ø§Ø¡ ÙˆØ§Ù„Ù†ÙˆØ§Ø¶Ø­
        """
    ]

    # Combine texts for analysis
    combined_text = '\n'.join(sample_texts)

    print(f"âœ… Loaded {len(sample_texts)} samples ({len(combined_text):,} characters)")

    # Perform analyses
    results = {}
    results['diacritics'] = analyzer.analyze_diacritics(combined_text)
    results['formatting'] = analyzer.analyze_formatting_patterns(combined_text)
    results['islamic_terms'] = analyzer.analyze_islamic_terminology(combined_text)
    results['character_dist'] = analyzer.analyze_character_distribution(combined_text)
    results['text_structure'] = analyzer.analyze_text_structure(combined_text)

    return results


def generate_analysis_report(results: Dict) -> str:
    """Generate comprehensive analysis report."""
    report = []
    report.append("# ğŸ“Š Arabic Text Characteristics Analysis")
    report.append("*Comprehensive analysis of Arabic books dataset for OCR training*\n")

    if not results:
        report.append("âŒ **Analysis failed - could not load dataset**\n")
        return '\n'.join(report)

    # Diacritics Analysis
    report.append("## ğŸ”¤ Diacritics Analysis")
    diac = results['diacritics']
    report.append(f"- **Total characters**: {diac['total_chars']:,}")
    report.append(f"- **Arabic characters**: {diac['arabic_chars']:,}")
    report.append(f"- **Total diacritics**: {diac['total_diacritics']:,}")
    report.append(f"- **Diacritic ratio**: {diac['diacritic_ratio']:.3f}")

    if diac['most_common_diacritics']:
        report.append("\n**Most common diacritics:**")
        for diacritic, count in diac['most_common_diacritics']:
            report.append(f"- {diacritic}: {count:,}")

    # Formatting Patterns
    report.append("\n## ğŸ“ Formatting Patterns")
    formatting = results['formatting']
    for pattern_type, data in formatting.items():
        report.append(f"\n**{pattern_type.replace('_', ' ').title()}:**")
        report.append(f"- Count: {data['count']}")
        if data['examples']:
            report.append(f"- Examples: {', '.join(data['examples'][:3])}")

    # Islamic Terminology
    report.append("\n## ğŸ•Œ Islamic Terminology Analysis")
    islamic = results['islamic_terms']
    report.append(f"- **Total Islamic terms**: {islamic['total_islamic_terms']}")
    report.append(f"- **Unique term types**: {islamic['unique_terms']}")

    if islamic['term_frequencies']:
        report.append("\n**Most frequent terms:**")
        sorted_terms = sorted(islamic['term_frequencies'].items(),
                            key=lambda x: x[1], reverse=True)
        for term, count in sorted_terms[:5]:
            report.append(f"- {term}: {count}")

    # Character Distribution
    report.append("\n## ğŸ”¤ Character Distribution")
    chars = results['character_dist']
    report.append(f"- **Unique Arabic characters**: {chars['unique_characters']}")
    report.append(f"- **Total Arabic characters**: {chars['total_arabic_chars']:,}")

    if chars['most_common_chars']:
        report.append("\n**Most frequent characters:**")
        for char, count in chars['most_common_chars'][:10]:
            report.append(f"- {char}: {count:,}")

    # Text Structure
    report.append("\n## ğŸ“„ Text Structure Analysis")
    struct = results['text_structure']
    report.append(f"- **Total lines**: {struct['total_lines']:,}")
    report.append(f"- **Non-empty lines**: {struct['non_empty_lines']:,}")
    report.append(f"- **Total words**: {struct['total_words']:,}")
    report.append(f"- **Average line length**: {struct['avg_line_length']:.1f} chars")
    report.append(f"- **Average word length**: {struct['avg_word_length']:.1f} chars")
    report.append(f"- **Max line length**: {struct['max_line_length']} chars")

    # Recommendations
    report.append("\n## ğŸ¯ OCR Training Recommendations")
    report.append("Based on the analysis:")

    diacritic_ratio = results['diacritics']['diacritic_ratio']
    if diacritic_ratio < 0.1:
        report.append("- âœ… **Low diacritic density** - good for initial OCR training")
    else:
        report.append("- âš ï¸ **High diacritic density** - will need careful handling")

    islamic_terms = results['islamic_terms']['total_islamic_terms']
    if islamic_terms > 100:
        report.append("- âœ… **Rich Islamic terminology** - perfect for classical texts")

    avg_line = struct['avg_line_length']
    if avg_line > 50:
        report.append("- âš ï¸ **Long lines** - may need line segmentation")

    report.append("\n## ğŸš€ Next Steps for Section 1.3")
    report.append("1. **Configure MLflow for Arabic OCR experiments**")
    report.append("2. **Set up Arabic text evaluation metrics (CER, WER, BLEU)**")
    report.append("3. **Create OCR-specific logging and tracking**")
    report.append("4. **Begin Nougat model integration testing**")

    return '\n'.join(report)


def main():
    """Main analysis function."""
    print("ğŸ•Œ Arabic Text Characteristics Analyzer")
    print("=" * 50)

    # Perform analysis
    results = analyze_dataset_sample()

    # Generate report
    report = generate_analysis_report(results)

    # Save report
    output_file = "arabic_text_characteristics_report.md"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nâœ… Analysis complete!")
    print(f"ğŸ“„ Report saved to: {output_file}")
    print(f"ğŸ¯ Section 1.2 analysis is now complete!")


if __name__ == "__main__":
    main()